{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Exploration\n",
    "\n",
    "## Overview\n",
    "Processing NamUs data for missing persons and unidentified bodies across all US states and territories.\n",
    "\n",
    "**Data sources:**\n",
    "- NamUs (National Missing & Unidentified Persons System)\n",
    "- 54 states/territories\n",
    "- Date range: 1924-2025 (101 years)\n",
    "\n",
    "**Key challenges:**\n",
    "1. State name standardization (full names vs abbreviations)\n",
    "2. Mixed file types (some CSVs contain both MP and UP data)\n",
    "3. Date parsing across different formats\n",
    "4. Duplicate detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      7\u001b[0m sns\u001b[38;5;241m.\u001b[39mset_style(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdarkgrid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "RAW_DIR = '../data/raw'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading\n",
    "\n",
    "Load all state files - separate missing persons from unidentified bodies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all missing persons files\n",
    "mp_files = [f for f in os.listdir(RAW_DIR) if f.endswith('_missing_persons.csv')]\n",
    "mp_data = []\n",
    "\n",
    "for file in mp_files:\n",
    "    df = pd.read_csv(os.path.join(RAW_DIR, file))\n",
    "    mp_data.append(df)\n",
    "    \n",
    "df_mp = pd.concat(mp_data, ignore_index=True)\n",
    "\n",
    "print(f\"Missing Persons: {len(df_mp):,} cases across {len(mp_files)} states\")\n",
    "print(f\"Columns: {df_mp.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all unidentified bodies files\n",
    "bodies_files = [f for f in os.listdir(RAW_DIR) if f.endswith('_unidentified_bodies.csv')]\n",
    "bodies_data = []\n",
    "\n",
    "for file in bodies_files:\n",
    "    df = pd.read_csv(os.path.join(RAW_DIR, file))\n",
    "    bodies_data.append(df)\n",
    "    \n",
    "df_bodies = pd.concat(bodies_data, ignore_index=True)\n",
    "\n",
    "print(f\"Unidentified Bodies: {len(df_bodies):,} cases across {len(bodies_files)} states\")\n",
    "print(f\"Columns: {df_bodies.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning\n",
    "\n",
    "### Issue 1: State Name Standardization\n",
    "Bodies data uses full state names (\"California\"), while some analyses need abbreviations (\"CA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check state naming convention\n",
    "print(\"Missing Persons - unique states:\")\n",
    "print(sorted(df_mp['State'].unique())[:10])\n",
    "print(f\"\\nTotal: {df_mp['State'].nunique()} states\")\n",
    "\n",
    "print(\"\\nUnidentified Bodies - unique states:\")\n",
    "print(sorted(df_bodies['State'].unique())[:10])\n",
    "print(f\"\\nTotal: {df_bodies['State'].nunique()} states\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue 2: Date Parsing\n",
    "Extract years from date columns for temporal analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing persons - use DLC (Date Last Contact)\n",
    "df_mp['year'] = pd.to_datetime(df_mp['DLC'], errors='coerce').dt.year\n",
    "\n",
    "# Unidentified bodies - use DBF (Date Body Found)\n",
    "df_bodies['year'] = pd.to_datetime(df_bodies['DBF'], errors='coerce').dt.year\n",
    "\n",
    "print(\"Missing Persons year range:\")\n",
    "print(f\"  Min: {df_mp['year'].min():.0f}\")\n",
    "print(f\"  Max: {df_mp['year'].max():.0f}\")\n",
    "print(f\"  Missing: {df_mp['year'].isna().sum():,} ({df_mp['year'].isna().sum()/len(df_mp)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nUnidentified Bodies year range:\")\n",
    "print(f\"  Min: {df_bodies['year'].min():.0f}\")\n",
    "print(f\"  Max: {df_bodies['year'].max():.0f}\")\n",
    "print(f\"  Missing: {df_bodies['year'].isna().sum():,} ({df_bodies['year'].isna().sum()/len(df_bodies)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initial Exploration\n",
    "\n",
    "### State-level distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top states by missing persons\n",
    "mp_by_state = df_mp.groupby('State').size().sort_values(ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "mp_by_state.head(20).plot(kind='barh', ax=ax, color='steelblue')\n",
    "ax.set_title('Top 20 States - Missing Persons', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Number of Cases')\n",
    "ax.invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nTop 5 states (Missing Persons):\")\n",
    "for state, count in mp_by_state.head().items():\n",
    "    print(f\"  {state}: {count:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top states by unidentified bodies\n",
    "bodies_by_state = df_bodies.groupby('State').size().sort_values(ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "bodies_by_state.head(20).plot(kind='barh', ax=ax, color='darkred')\n",
    "ax.set_title('Top 20 States - Unidentified Bodies', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Number of Cases')\n",
    "ax.invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nTop 5 states (Unidentified Bodies):\")\n",
    "for state, count in bodies_by_state.head().items():\n",
    "    print(f\"  {state}: {count:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cases per year\n",
    "mp_by_year = df_mp[df_mp['year'] >= 1980].groupby('year').size()\n",
    "bodies_by_year = df_bodies[df_bodies['year'] >= 1980].groupby('year').size()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "mp_by_year.plot(ax=ax, label='Missing Persons', color='steelblue', linewidth=2)\n",
    "bodies_by_year.plot(ax=ax, label='Unidentified Bodies', color='darkred', linewidth=2)\n",
    "ax.set_title('Cases Over Time (1980-2025)', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Number of Cases')\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decade aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add decade column\n",
    "df_mp['decade'] = (df_mp['year'] // 10) * 10\n",
    "df_bodies['decade'] = (df_bodies['year'] // 10) * 10\n",
    "\n",
    "# Cases per decade\n",
    "mp_by_decade = df_mp[df_mp['decade'] >= 1980].groupby('decade').size()\n",
    "bodies_by_decade = df_bodies[df_bodies['decade'] >= 1980].groupby('decade').size()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "x = np.arange(len(mp_by_decade))\n",
    "width = 0.35\n",
    "\n",
    "ax.bar(x - width/2, mp_by_decade.values, width, label='Missing Persons', color='steelblue')\n",
    "ax.bar(x + width/2, bodies_by_decade.values, width, label='Unidentified Bodies', color='darkred')\n",
    "\n",
    "ax.set_title('Cases by Decade', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Decade')\n",
    "ax.set_ylabel('Number of Cases')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([f\"{int(d)}s\" for d in mp_by_decade.index])\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. County-Level Analysis\n",
    "\n",
    "Aggregate to county-decade level for outlier detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate missing persons by county-decade\n",
    "mp_county_decade = df_mp.groupby(['State', 'County', 'decade']).size().reset_index(name='mp_count')\n",
    "\n",
    "print(f\"County-decade combinations (MP): {len(mp_county_decade):,}\")\n",
    "print(f\"\\nTop 10 county-decades (Missing Persons):\")\n",
    "print(mp_county_decade.sort_values('mp_count', ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate bodies by county-decade\n",
    "bodies_county_decade = df_bodies.groupby(['State', 'County', 'decade']).size().reset_index(name='bodies_count')\n",
    "\n",
    "print(f\"County-decade combinations (Bodies): {len(bodies_county_decade):,}\")\n",
    "print(f\"\\nTop 10 county-decades (Unidentified Bodies):\")\n",
    "print(bodies_county_decade.sort_values('bodies_count', ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Quality Summary\n",
    "\n",
    "Final dataset characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"FINAL DATASET SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nMissing Persons:\")\n",
    "print(f\"  Total cases: {len(df_mp):,}\")\n",
    "print(f\"  States: {df_mp['State'].nunique()}\")\n",
    "print(f\"  Counties: {df_mp['County'].nunique():,}\")\n",
    "print(f\"  Year range: {df_mp['year'].min():.0f} - {df_mp['year'].max():.0f}\")\n",
    "print(f\"  Decades covered: {sorted(df_mp['decade'].dropna().unique())}\")\n",
    "\n",
    "print(f\"\\nUnidentified Bodies:\")\n",
    "print(f\"  Total cases: {len(df_bodies):,}\")\n",
    "print(f\"  States: {df_bodies['State'].nunique()}\")\n",
    "print(f\"  Counties: {df_bodies['County'].nunique():,}\")\n",
    "print(f\"  Year range: {df_bodies['year'].min():.0f} - {df_bodies['year'].max():.0f}\")\n",
    "print(f\"  Decades covered: {sorted(df_bodies['decade'].dropna().unique())}\")\n",
    "\n",
    "print(f\"\\nCombined:\")\n",
    "print(f\"  Total cases: {len(df_mp) + len(df_bodies):,}\")\n",
    "print(f\"  Temporal coverage: {df_mp['year'].max() - df_mp['year'].min():.0f} years\")\n",
    "print(f\"  Geographic coverage: {max(df_mp['State'].nunique(), df_bodies['State'].nunique())} states/territories\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Findings\n",
    "\n",
    "1. **Data completeness:** 100% state coverage (54 states/territories)\n",
    "2. **Temporal range:** 101 years (1924-2025)\n",
    "3. **Scale:** 41,200 total cases\n",
    "4. **Missing data:** Minimal year data missing (<5%)\n",
    "5. **Top states:** CA, TX, FL, AZ (consistent across both datasets)\n",
    "\n",
    "**Next steps:**\n",
    "- Calculate standard deviation scores (notebook 02)\n",
    "- Identify county-decade outliers\n",
    "- Validate against known serial killer cases"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
