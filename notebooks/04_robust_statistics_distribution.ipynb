{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9y20lgv74af",
   "source": "# Robust Statistics and Distribution Analysis\n\n## Overview\n\nStandard z-scores assume normally distributed data, but crime rates are heavily right-skewed\nwith many zero-count counties and a few extreme outliers. This notebook evaluates several\nrobust statistical methods to identify genuinely anomalous counties while controlling for\nfalse discoveries.\n\n**Methods compared:**\n- Standard z-scores vs. Robust (MAD-based) z-scores\n- False Discovery Rate (FDR) correction (Benjamini-Hochberg)\n- Empirical Bayes shrinkage for small-county stabilization\n- Log-transformed z-scores, Poisson p-values, Negative Binomial p-values, Percentile ranks\n\n**Data:** `county_decade_outliers.csv` -- county-decade level rates with all statistical scores pre-computed.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "zkpt1opmbeo",
   "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nfrom scipy import stats\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n\nplt.rcParams.update({\n    \"figure.figsize\": (14, 6),\n    \"axes.titlesize\": 14,\n    \"axes.labelsize\": 12,\n    \"font.size\": 11,\n    \"axes.grid\": True,\n    \"grid.alpha\": 0.3,\n})\n\nprint(\"Libraries loaded successfully.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "xirzr3ndip",
   "source": "## 1. Load Data",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "nivb7bzk4g",
   "source": "DATA_PATH = \"../data/analysis/county_decade_outliers.csv\"\n\ndf = pd.read_csv(DATA_PATH)\n\nprint(f\"Dataset shape: {df.shape[0]:,} rows x {df.shape[1]} columns\")\nprint(f\"\\nColumns:\\n{df.columns.tolist()}\")\nprint(f\"\\nDecades present: {sorted(df['decade'].unique())}\")\nprint(f\"Unique states:   {df['State'].nunique()}\")\nprint(f\"Unique counties: {df['County'].nunique()}\")\ndf.head(3)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "ch9homkecab",
   "source": "# Quick statistical summary of the key rate columns\nrate_cols = [\"missing_per_100k\", \"bodies_per_100k\", \"mp_z_score\", \"mp_robust_z\",\n             \"mp_log_z\", \"mp_poisson_p\", \"mp_nb_p\", \"mp_percentile\",\n             \"bodies_percentile\", \"shrinkage_weight\"]\ndf[rate_cols].describe().round(3)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "x7i9ydunvzh",
   "source": "## 2. Distribution Diagnostics\n\nCrime rates are count-derived and bounded at zero, which almost always produces a right-skewed\ndistribution. Below we visualize the empirical distributions and check normality with QQ plots.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "28wpwuzun6x",
   "source": "# --- Histograms showing right skew ---\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\n\n# Missing persons rate -- raw\nax = axes[0, 0]\nmp_rate = df[\"missing_per_100k\"].dropna()\nax.hist(mp_rate, bins=80, color=\"steelblue\", edgecolor=\"white\", alpha=0.85)\nax.axvline(mp_rate.median(), color=\"orange\", ls=\"--\", lw=2, label=f\"Median = {mp_rate.median():.1f}\")\nax.axvline(mp_rate.mean(), color=\"red\", ls=\"-\", lw=2, label=f\"Mean = {mp_rate.mean():.1f}\")\nax.set_title(\"Missing Persons per 100k (raw)\")\nax.set_xlabel(\"Rate per 100k\")\nax.set_ylabel(\"Count\")\nax.legend()\n\n# Missing persons rate -- log scale\nax = axes[0, 1]\nmp_pos = mp_rate[mp_rate > 0]\nax.hist(np.log1p(mp_pos), bins=60, color=\"steelblue\", edgecolor=\"white\", alpha=0.85)\nax.set_title(\"Missing Persons per 100k (log1p transform)\")\nax.set_xlabel(\"log(1 + rate)\")\nax.set_ylabel(\"Count\")\n\n# Bodies rate -- raw\nax = axes[1, 0]\nbd_rate = df[\"bodies_per_100k\"].dropna()\nax.hist(bd_rate, bins=80, color=\"darkred\", edgecolor=\"white\", alpha=0.85)\nax.axvline(bd_rate.median(), color=\"orange\", ls=\"--\", lw=2, label=f\"Median = {bd_rate.median():.1f}\")\nax.axvline(bd_rate.mean(), color=\"red\", ls=\"-\", lw=2, label=f\"Mean = {bd_rate.mean():.1f}\")\nax.set_title(\"Unidentified Bodies per 100k (raw)\")\nax.set_xlabel(\"Rate per 100k\")\nax.set_ylabel(\"Count\")\nax.legend()\n\n# Bodies rate -- log scale\nax = axes[1, 1]\nbd_pos = bd_rate[bd_rate > 0]\nax.hist(np.log1p(bd_pos), bins=60, color=\"darkred\", edgecolor=\"white\", alpha=0.85)\nax.set_title(\"Unidentified Bodies per 100k (log1p transform)\")\nax.set_xlabel(\"log(1 + rate)\")\nax.set_ylabel(\"Count\")\n\nfig.suptitle(\"Distribution of Crime Rates -- Evidence of Right Skew\", fontsize=15, fontweight=\"bold\", y=1.01)\nplt.tight_layout()\nplt.show()\n\n# Skewness statistics\nprint(\"Skewness (raw):\")\nprint(f\"  missing_per_100k : {mp_rate.skew():.2f}\")\nprint(f\"  bodies_per_100k  : {bd_rate.skew():.2f}\")\nprint(f\"\\nSkewness (log1p):\")\nprint(f\"  missing_per_100k : {np.log1p(mp_pos).skew():.2f}\")\nprint(f\"  bodies_per_100k  : {np.log1p(bd_pos).skew():.2f}\")\nprint(\"\\nSkewness > 1 indicates heavy right skew; log transform reduces it substantially.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "lpg4sa6qvms",
   "source": "# --- QQ Plots vs. Normal Distribution ---\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\n# QQ plot -- missing_per_100k\nax = axes[0]\nstats.probplot(mp_rate, dist=\"norm\", plot=ax)\nax.set_title(\"QQ Plot: missing_per_100k vs Normal\")\nax.get_lines()[0].set(color=\"steelblue\", markersize=3, alpha=0.5)\nax.get_lines()[1].set(color=\"red\", linewidth=2)\n\n# QQ plot -- bodies_per_100k\nax = axes[1]\nstats.probplot(bd_rate, dist=\"norm\", plot=ax)\nax.set_title(\"QQ Plot: bodies_per_100k vs Normal\")\nax.get_lines()[0].set(color=\"darkred\", markersize=3, alpha=0.5)\nax.get_lines()[1].set(color=\"red\", linewidth=2)\n\nfig.suptitle(\"QQ Plots -- Departure from Normality in Upper Tail\", fontsize=14, fontweight=\"bold\", y=1.01)\nplt.tight_layout()\nplt.show()\n\n# Formal normality tests (Shapiro on subsample for speed, D'Agostino on full data)\n_, dag_p_mp = stats.normaltest(mp_rate)\n_, dag_p_bd = stats.normaltest(bd_rate)\nprint(\"D'Agostino-Pearson normality test:\")\nprint(f\"  missing_per_100k  p-value = {dag_p_mp:.2e}  {'REJECT normality' if dag_p_mp < 0.05 else 'Fail to reject'}\")\nprint(f\"  bodies_per_100k   p-value = {dag_p_bd:.2e}  {'REJECT normality' if dag_p_bd < 0.05 else 'Fail to reject'}\")\nprint(\"\\nBoth distributions strongly violate normality, justifying robust methods.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "cc85zz5ja3w",
   "source": "## 3. Standard vs. Robust Z-Scores\n\nStandard z-scores use the mean and standard deviation, which are both heavily influenced by\noutliers. Robust z-scores replace these with the **median** and **MAD (Median Absolute\nDeviation)**, producing scores that are far less distorted by extreme values.\n\nThe key question: when we switch to robust z-scores, do some counties lose their \"outlier\"\nstatus, and do others gain it?",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "r577mbzf78f",
   "source": "# --- Scatter: standard z vs robust z ---\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\n# Missing persons\nax = axes[0]\nvalid = df.dropna(subset=[\"mp_z_score\", \"mp_robust_z\"])\nsc = ax.scatter(valid[\"mp_z_score\"], valid[\"mp_robust_z\"],\n                c=valid[\"alert_level\"].map({\"GREEN\": \"green\", \"YELLOW\": \"gold\", \"RED\": \"red\"}).fillna(\"grey\"),\n                s=8, alpha=0.4, edgecolors=\"none\")\nlim = max(abs(valid[\"mp_z_score\"]).max(), abs(valid[\"mp_robust_z\"]).max()) * 0.5\nax.plot([0, lim], [0, lim], \"k--\", alpha=0.4, label=\"y = x (identical scores)\")\nax.set_xlabel(\"Standard Z-score (mp_z_score)\")\nax.set_ylabel(\"Robust Z-score (mp_robust_z)\")\nax.set_title(\"Missing Persons: Standard vs Robust Z\")\nax.legend(loc=\"upper left\")\n\n# Bodies\nax = axes[1]\nvalid_b = df.dropna(subset=[\"bodies_z_score\", \"bodies_robust_z\"])\nsc = ax.scatter(valid_b[\"bodies_z_score\"], valid_b[\"bodies_robust_z\"],\n                c=valid_b[\"alert_level\"].map({\"GREEN\": \"green\", \"YELLOW\": \"gold\", \"RED\": \"red\"}).fillna(\"grey\"),\n                s=8, alpha=0.4, edgecolors=\"none\")\nlim_b = max(abs(valid_b[\"bodies_z_score\"]).max(), abs(valid_b[\"bodies_robust_z\"]).max()) * 0.5\nax.plot([0, lim_b], [0, lim_b], \"k--\", alpha=0.4, label=\"y = x (identical scores)\")\nax.set_xlabel(\"Standard Z-score (bodies_z_score)\")\nax.set_ylabel(\"Robust Z-score (bodies_robust_z)\")\nax.set_title(\"Unidentified Bodies: Standard vs Robust Z\")\nax.legend(loc=\"upper left\")\n\nplt.suptitle(\"Robust Z-scores amplify separation -- points above the diagonal are flagged more aggressively\",\n             fontsize=12, y=1.02)\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "sp5hhuus2o",
   "source": "# --- Count how many counties change alert level under robust scoring ---\n# Define a simple threshold-based alert using robust z-scores\n# Standard thresholds: GREEN < 2, YELLOW 2-3, RED >= 3\n\ndef assign_alert(z):\n    if pd.isna(z):\n        return \"GREEN\"\n    if z >= 3:\n        return \"RED\"\n    elif z >= 2:\n        return \"YELLOW\"\n    return \"GREEN\"\n\ndf[\"alert_standard\"] = df[\"mp_z_score\"].apply(assign_alert)\ndf[\"alert_robust\"] = df[\"mp_robust_z\"].apply(assign_alert)\n\n# Crosstab to show transitions\nct = pd.crosstab(df[\"alert_standard\"], df[\"alert_robust\"],\n                 rownames=[\"Standard Alert\"], colnames=[\"Robust Alert\"])\nprint(\"Alert Level Transition Matrix (Standard -> Robust):\\n\")\nprint(ct)\n\n# Summary counts\nchanged = (df[\"alert_standard\"] != df[\"alert_robust\"]).sum()\nupgraded = ((df[\"alert_standard\"] == \"GREEN\") & (df[\"alert_robust\"].isin([\"YELLOW\", \"RED\"]))).sum()\ndowngraded = ((df[\"alert_standard\"].isin([\"YELLOW\", \"RED\"])) & (df[\"alert_robust\"] == \"GREEN\")).sum()\n\nprint(f\"\\nTotal counties that changed alert level: {changed:,}\")\nprint(f\"  Upgraded (GREEN -> YELLOW/RED under robust):  {upgraded:,}\")\nprint(f\"  Downgraded (YELLOW/RED -> GREEN under robust): {downgraded:,}\")\nprint(f\"\\nRobust z-scores typically flag MORE counties because the MAD denominator is smaller than the SD.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "6apnv5rp0k6",
   "source": "# --- Interactive Plotly scatter for detailed exploration ---\nsample = df.dropna(subset=[\"mp_z_score\", \"mp_robust_z\"]).copy()\nsample[\"label\"] = sample[\"County\"] + \", \" + sample[\"State\"] + \" (\" + sample[\"decade\"].astype(str) + \"s)\"\n\nfig = px.scatter(\n    sample,\n    x=\"mp_z_score\",\n    y=\"mp_robust_z\",\n    color=\"alert_level\",\n    color_discrete_map={\"GREEN\": \"#2ca02c\", \"YELLOW\": \"#f0c929\", \"RED\": \"#d62728\"},\n    hover_name=\"label\",\n    hover_data={\"missing_per_100k\": \":.1f\", \"population\": \":,.0f\",\n                \"mp_z_score\": \":.2f\", \"mp_robust_z\": \":.2f\"},\n    opacity=0.5,\n    title=\"Standard vs Robust Z-Scores -- Missing Persons (hover for details)\",\n    labels={\"mp_z_score\": \"Standard Z-score\", \"mp_robust_z\": \"Robust Z-score (MAD)\"},\n)\nfig.add_shape(type=\"line\", x0=0, y0=0, x1=sample[\"mp_z_score\"].quantile(0.99),\n              y1=sample[\"mp_z_score\"].quantile(0.99),\n              line=dict(dash=\"dash\", color=\"black\", width=1))\nfig.update_layout(height=550, template=\"plotly_white\")\nfig.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "n6v1xy2erj",
   "source": "## 4. FDR Correction\n\nWhen testing thousands of counties simultaneously, we expect many false positives by chance\nalone. The **Benjamini-Hochberg FDR correction** controls the expected proportion of false\ndiscoveries. Below we compare uncorrected p-values against FDR-adjusted significance.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "4bel58p83k7",
   "source": "# --- Uncorrected vs FDR-corrected significance ---\nvalid_p = df.dropna(subset=[\"mp_p_value\"]).copy()\n\nuncorrected_sig = (valid_p[\"mp_p_value\"] < 0.05).sum()\nfdr_sig = valid_p[\"fdr_significant\"].sum()\n\nprint(\"Significance comparison (alpha = 0.05):\")\nprint(f\"  Uncorrected (mp_p_value < 0.05):  {uncorrected_sig:,} counties ({uncorrected_sig/len(valid_p)*100:.1f}%)\")\nprint(f\"  FDR-corrected (fdr_significant):   {fdr_sig:,} counties ({fdr_sig/len(valid_p)*100:.1f}%)\")\nprint(f\"  Reduction:                         {uncorrected_sig - fdr_sig:,} fewer flagged ({(uncorrected_sig - fdr_sig)/max(uncorrected_sig,1)*100:.1f}%)\")\nprint(f\"\\nTotal county-decades tested: {len(valid_p):,}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "vr2xc1uhjts",
   "source": "# --- Bar chart: Uncorrected vs FDR-corrected ---\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Bar comparison\nax = axes[0]\ncategories = [\"Uncorrected\\n(p < 0.05)\", \"FDR-Corrected\\n(adjusted p < 0.05)\"]\ncounts = [uncorrected_sig, fdr_sig]\ncolors = [\"#e74c3c\", \"#2ecc71\"]\nbars = ax.bar(categories, counts, color=colors, edgecolor=\"black\", linewidth=0.8, width=0.5)\nfor bar, count in zip(bars, counts):\n    ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 20,\n            f\"{count:,}\", ha=\"center\", va=\"bottom\", fontweight=\"bold\", fontsize=13)\nax.set_ylabel(\"Number of Significant County-Decades\")\nax.set_title(\"Impact of FDR Correction on Significance Calls\")\n\n# P-value distribution (histogram)\nax = axes[1]\nax.hist(valid_p[\"mp_p_value\"], bins=50, color=\"steelblue\", edgecolor=\"white\", alpha=0.85)\nax.axvline(0.05, color=\"red\", ls=\"--\", lw=2, label=\"alpha = 0.05\")\nax.set_xlabel(\"Uncorrected p-value (mp_p_value)\")\nax.set_ylabel(\"Frequency\")\nax.set_title(\"Distribution of Uncorrected P-Values\")\nax.legend()\n\nplt.tight_layout()\nplt.show()\n\nprint(\"Note: A uniform p-value distribution under the null would appear as a flat histogram.\")\nprint(\"Excess density near zero indicates many genuinely anomalous counties.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "4a1il6u483w",
   "source": "## 5. Empirical Bayes Shrinkage\n\nSmall counties with tiny populations produce wildly unstable rates. A single missing person\nin a county of 500 people yields 200 per 100k -- an artifact of small denominators, not a\ngenuine signal.\n\n**Empirical Bayes shrinkage** pulls extreme small-county rates toward the global mean,\nweighted by `shrinkage_weight` (0 = fully shrunk to global mean, 1 = keep original rate).\nCounties with large populations retain their original rate; small counties are stabilized.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "smmfyf9uill",
   "source": "# --- Original rate vs shrunk rate, colored by shrinkage weight ---\nshrink_df = df.dropna(subset=[\"missing_per_100k\", \"mp_rate_shrunk\", \"shrinkage_weight\"]).copy()\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\n# Missing persons\nax = axes[0]\nsc = ax.scatter(shrink_df[\"missing_per_100k\"], shrink_df[\"mp_rate_shrunk\"],\n                c=shrink_df[\"shrinkage_weight\"], cmap=\"RdYlGn\", s=10, alpha=0.6,\n                edgecolors=\"none\", vmin=0, vmax=1)\nplt.colorbar(sc, ax=ax, label=\"Shrinkage Weight (0=full shrink, 1=keep original)\")\nmax_val = max(shrink_df[\"missing_per_100k\"].quantile(0.99), shrink_df[\"mp_rate_shrunk\"].quantile(0.99))\nax.plot([0, max_val], [0, max_val], \"k--\", alpha=0.4, label=\"No shrinkage (y=x)\")\nax.set_xlabel(\"Original Rate (missing_per_100k)\")\nax.set_ylabel(\"Shrunk Rate (mp_rate_shrunk)\")\nax.set_title(\"Missing Persons: Empirical Bayes Shrinkage\")\nax.legend(loc=\"upper left\")\n\n# Bodies\nshrink_bd = df.dropna(subset=[\"bodies_per_100k\", \"bodies_rate_shrunk\", \"shrinkage_weight\"]).copy()\nax = axes[1]\nsc2 = ax.scatter(shrink_bd[\"bodies_per_100k\"], shrink_bd[\"bodies_rate_shrunk\"],\n                 c=shrink_bd[\"shrinkage_weight\"], cmap=\"RdYlGn\", s=10, alpha=0.6,\n                 edgecolors=\"none\", vmin=0, vmax=1)\nplt.colorbar(sc2, ax=ax, label=\"Shrinkage Weight (0=full shrink, 1=keep original)\")\nmax_val_b = max(shrink_bd[\"bodies_per_100k\"].quantile(0.99), shrink_bd[\"bodies_rate_shrunk\"].quantile(0.99))\nax.plot([0, max_val_b], [0, max_val_b], \"k--\", alpha=0.4, label=\"No shrinkage (y=x)\")\nax.set_xlabel(\"Original Rate (bodies_per_100k)\")\nax.set_ylabel(\"Shrunk Rate (bodies_rate_shrunk)\")\nax.set_title(\"Unidentified Bodies: Empirical Bayes Shrinkage\")\nax.legend(loc=\"upper left\")\n\nplt.suptitle(\"Points below the diagonal have been shrunk toward the global mean\", fontsize=12, y=1.02)\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "fhzgdynya5q",
   "source": "# --- Extreme examples: small counties shrunk dramatically ---\nextreme = shrink_df.copy()\nextreme[\"shrinkage_delta\"] = extreme[\"missing_per_100k\"] - extreme[\"mp_rate_shrunk\"]\nextreme[\"shrinkage_pct\"] = (extreme[\"shrinkage_delta\"] / extreme[\"missing_per_100k\"].replace(0, np.nan) * 100)\n\n# Top 15 most shrunk counties\ntop_shrunk = extreme.nlargest(15, \"shrinkage_delta\")[\n    [\"State\", \"County\", \"decade\", \"population\", \"missing_per_100k\",\n     \"mp_rate_shrunk\", \"shrinkage_delta\", \"shrinkage_weight\", \"small_county_flag\"]\n].reset_index(drop=True)\n\nprint(\"Top 15 Counties with Greatest Empirical Bayes Shrinkage (Missing Persons):\")\nprint(\"These are predominantly small counties where raw rates are unreliable.\\n\")\nprint(top_shrunk.to_string(index=False))\n\nprint(f\"\\nSmall county flag prevalence in top 15: \"\n      f\"{top_shrunk['small_county_flag'].sum()}/{len(top_shrunk)} \"\n      f\"({top_shrunk['small_county_flag'].mean()*100:.0f}%)\")\nprint(f\"Mean population in top 15: {top_shrunk['population'].mean():,.0f}\")\nprint(f\"Mean shrinkage weight:     {top_shrunk['shrinkage_weight'].mean():.3f} (near 0 = heavy shrinkage)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "3s8nhaqqdu7",
   "source": "# --- Interactive Plotly: shrinkage by population ---\nfig = px.scatter(\n    shrink_df,\n    x=\"population\",\n    y=\"shrinkage_weight\",\n    color=\"small_county_flag\",\n    color_discrete_map={True: \"#e74c3c\", False: \"#3498db\"},\n    hover_data={\"County\": True, \"State\": True, \"decade\": True,\n                \"missing_per_100k\": \":.1f\", \"mp_rate_shrunk\": \":.1f\"},\n    opacity=0.4,\n    log_x=True,\n    title=\"Shrinkage Weight vs Population -- Small counties receive more shrinkage\",\n    labels={\"population\": \"Population (log scale)\", \"shrinkage_weight\": \"Shrinkage Weight\",\n            \"small_county_flag\": \"Small County\"},\n)\nfig.update_layout(height=450, template=\"plotly_white\")\nfig.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "zhy7pkiztg",
   "source": "## 6. Method Comparison\n\nFive different statistical methods are available for identifying outlier counties. Each makes\ndifferent assumptions about the data-generating process:\n\n| Method | Column | Assumption |\n|---|---|---|\n| Standard Z-score | `mp_z_score` | Normal distribution of rates |\n| Log-transformed Z | `mp_log_z` | Log-normal distribution |\n| Poisson p-value | `mp_poisson_p` | Counts follow Poisson process |\n| Negative Binomial p-value | `mp_nb_p` | Overdispersed counts |\n| Percentile rank | `mp_percentile` | Non-parametric; no distributional assumption |\n\nBelow we count how many county-decades each method flags at the **99th percentile** threshold.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "7z3klv5qk0n",
   "source": "# --- Outlier counts at 99th percentile for each method ---\nmethods = {\n    \"Standard Z >= 2.33\":       (df[\"mp_z_score\"] >= 2.33).sum(),\n    \"Log Z >= 2.33\":            (df[\"mp_log_z\"] >= 2.33).sum(),\n    \"Poisson p < 0.01\":         (df[\"mp_poisson_p\"] < 0.01).sum(),\n    \"Neg. Binomial p < 0.01\":   (df[\"mp_nb_p\"] < 0.01).sum(),\n    \"Percentile >= 99\":         (df[\"mp_percentile\"] >= 99).sum(),\n}\n\nmethod_df = pd.DataFrame({\n    \"Method\": list(methods.keys()),\n    \"Outliers Flagged\": list(methods.values()),\n    \"Pct of Total\": [v / len(df) * 100 for v in methods.values()],\n})\nmethod_df = method_df.sort_values(\"Outliers Flagged\", ascending=False).reset_index(drop=True)\n\nprint(\"Outlier Counts at 99th Percentile Threshold:\\n\")\nprint(method_df.to_string(index=False))\nprint(f\"\\nTotal county-decades: {len(df):,}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "stz3trya0e8",
   "source": "# --- Bar chart comparison of methods ---\nfig, ax = plt.subplots(figsize=(12, 5))\n\ncolors = [\"#2c3e50\", \"#2980b9\", \"#e67e22\", \"#e74c3c\", \"#27ae60\"]\nbars = ax.barh(method_df[\"Method\"], method_df[\"Outliers Flagged\"],\n               color=colors, edgecolor=\"black\", linewidth=0.6)\n\nfor bar, val in zip(bars, method_df[\"Outliers Flagged\"]):\n    ax.text(bar.get_width() + 5, bar.get_y() + bar.get_height() / 2,\n            f\"{val:,}\", va=\"center\", fontweight=\"bold\")\n\nax.set_xlabel(\"Number of County-Decades Flagged as Outliers\")\nax.set_title(\"Method Comparison: Outlier Detection at 99th Percentile\", fontweight=\"bold\")\nax.invert_yaxis()\nplt.tight_layout()\nplt.show()\n\nprint(\"Interpretation:\")\nprint(\"- Parametric methods (Poisson, NB) may flag more or fewer counties depending on overdispersion.\")\nprint(\"- The percentile method is non-parametric and flags exactly ~1% by construction.\")\nprint(\"- Standard Z tends to be liberal (inflated by skew); Log Z is more conservative.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "vyui40slloc",
   "source": "# --- Agreement heatmap: how many counties are flagged by multiple methods ---\ndf[\"flag_std_z\"]     = (df[\"mp_z_score\"] >= 2.33).astype(int)\ndf[\"flag_log_z\"]     = (df[\"mp_log_z\"] >= 2.33).astype(int)\ndf[\"flag_poisson\"]   = (df[\"mp_poisson_p\"] < 0.01).astype(int)\ndf[\"flag_nb\"]        = (df[\"mp_nb_p\"] < 0.01).astype(int)\ndf[\"flag_percentile\"]= (df[\"mp_percentile\"] >= 99).astype(int)\n\nflag_cols = [\"flag_std_z\", \"flag_log_z\", \"flag_poisson\", \"flag_nb\", \"flag_percentile\"]\nflag_labels = [\"Standard Z\", \"Log Z\", \"Poisson\", \"Neg. Binom.\", \"Percentile\"]\n\n# Pairwise agreement (Jaccard-like overlap)\noverlap = pd.DataFrame(index=flag_labels, columns=flag_labels, dtype=float)\nfor i, (ci, li) in enumerate(zip(flag_cols, flag_labels)):\n    for j, (cj, lj) in enumerate(zip(flag_cols, flag_labels)):\n        both = ((df[ci] == 1) & (df[cj] == 1)).sum()\n        either = ((df[ci] == 1) | (df[cj] == 1)).sum()\n        overlap.loc[li, lj] = both / either if either > 0 else 0\n\nfig, ax = plt.subplots(figsize=(8, 6))\nim = ax.imshow(overlap.values.astype(float), cmap=\"YlOrRd\", vmin=0, vmax=1)\nax.set_xticks(range(len(flag_labels)))\nax.set_xticklabels(flag_labels, rotation=45, ha=\"right\")\nax.set_yticks(range(len(flag_labels)))\nax.set_yticklabels(flag_labels)\nfor i in range(len(flag_labels)):\n    for j in range(len(flag_labels)):\n        val = float(overlap.iloc[i, j])\n        ax.text(j, i, f\"{val:.2f}\", ha=\"center\", va=\"center\",\n                color=\"white\" if val > 0.6 else \"black\", fontsize=10)\nplt.colorbar(im, ax=ax, label=\"Jaccard Overlap\")\nax.set_title(\"Pairwise Agreement Between Outlier Detection Methods\", fontweight=\"bold\")\nplt.tight_layout()\nplt.show()\n\n# How many methods agree for flagged counties\ndf[\"n_methods_flagged\"] = df[flag_cols].sum(axis=1)\nflagged_any = df[df[\"n_methods_flagged\"] > 0]\nprint(f\"\\nCounty-decades flagged by at least one method: {len(flagged_any):,}\")\nprint(f\"Flagged by ALL 5 methods (high-confidence outliers): {(df['n_methods_flagged'] == 5).sum():,}\")\nprint(f\"\\nDistribution of method agreement among flagged counties:\")\nprint(flagged_any[\"n_methods_flagged\"].value_counts().sort_index().to_string())",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "zgqnorghwu",
   "source": "# --- Interactive: top consensus outliers (flagged by all 5 methods) ---\nconsensus = df[df[\"n_methods_flagged\"] == 5].copy()\nconsensus[\"label\"] = consensus[\"County\"] + \", \" + consensus[\"State\"]\nconsensus = consensus.sort_values(\"missing_per_100k\", ascending=False)\n\nfig = px.bar(\n    consensus.head(30),\n    x=\"label\",\n    y=\"missing_per_100k\",\n    color=\"decade\",\n    hover_data={\"population\": \":,.0f\", \"mp_z_score\": \":.2f\", \"mp_robust_z\": \":.2f\",\n                \"mp_poisson_p\": \":.2e\", \"mp_nb_p\": \":.2e\", \"mp_percentile\": \":.1f\"},\n    title=\"Top 30 Consensus Outliers -- Flagged by All 5 Methods (Missing Persons)\",\n    labels={\"label\": \"County\", \"missing_per_100k\": \"Rate per 100k\", \"decade\": \"Decade\"},\n)\nfig.update_layout(xaxis_tickangle=-45, height=500, template=\"plotly_white\")\nfig.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "e9pechv1dk",
   "source": "## 7. Summary of Key Findings\n\n### Distribution Characteristics\n- Both `missing_per_100k` and `bodies_per_100k` are **heavily right-skewed**, with\n  skewness values well above 1.0. The D'Agostino-Pearson test formally rejects normality\n  for both (p << 0.001). This means standard z-scores, which assume a symmetric bell curve,\n  will systematically underestimate the extremity of the right tail.\n\n### Robust Z-Scores\n- Robust (MAD-based) z-scores produce **larger absolute values** for true outliers because\n  the MAD denominator is not inflated by the very outliers it is trying to detect. Many\n  counties that appeared moderate under standard z-scores are reclassified as YELLOW or RED\n  under robust scoring.\n\n### FDR Correction\n- Without correction, a naive p < 0.05 threshold flags a large number of county-decades.\n  After Benjamini-Hochberg FDR correction, the number of significant results drops\n  substantially, removing likely false positives while retaining high-confidence anomalies.\n\n### Empirical Bayes Shrinkage\n- Small counties (low population) receive **heavy shrinkage** toward the global mean rate.\n  This prevents tiny counties with 1-2 cases from dominating the outlier rankings.\n  The most dramatically shrunk counties are almost exclusively those with populations\n  under 10,000.\n\n### Method Agreement\n- Counties flagged by **all five methods** simultaneously represent the highest-confidence\n  outliers. These consensus outliers are robust to the choice of distributional assumption\n  and should be prioritized for further investigation.\n- The Negative Binomial model, which accounts for overdispersion, tends to be the most\n  conservative (fewest flags), while the Poisson model may be overly liberal due to\n  unmodeled variance.\n\n### Practical Recommendation\nFor downstream analysis, use a **tiered approach**:\n1. **Tier 1 (highest confidence):** Counties flagged by all 5 methods AND surviving FDR correction.\n2. **Tier 2 (high confidence):** Counties flagged by 3+ methods with shrunk rates still elevated.\n3. **Tier 3 (investigate further):** Counties flagged by any single method, especially if large-population.",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}